import os
from langchain.chains import Retrieval0A
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import CSVLoader
from langchain.vectorstores import DocArrayInMemorySearch
from IPython.display import display,Markdown
from langchain.indexes import VectorstoreIndexCreator
from langchain.embeddings import OpenAIEmbeddings
from dotenv import load_dotenv,find_dotenv
_=load_dotenv(find_dotenv())
import pandas as pd
#UI:langchainplus..
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain.evaluation.qa import QAGnerateChain
from langchain.chains import SimpleSequentialChain
from langchain.chains import SequentialChain
from langchain.chains.router import MultiPromptChain
from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser
from langchain.prompts import PromptTemplate
import langchain
#设置debug模式
langchain.debug=True
file=''
loader=CSVLoader(file)
data=loader.load()
index=VectorstoreIndexCreator(
    vectorstore_cls=DocArrayInMemorySearch
).from_loaders([loader])
llm=ChatOpenAI(temperature=0.0)
qa=Retrieval0A.from_cahin_type(
    llm=llm,
    chain_type="stuff",
    retriever=index.vectorstore.as_retriever(),
    verbose=True,
    chain_type_kwargs={
        "document_seperator":"<<<<>>>>>"
    }
)
example_gen_chain= QAGnerateChain.from_llm(ChatOpenAI())
#示例问题和答案
examples=example_gen_chain.apply_and_parse(
    [{"doc":t} for t in data[:5]]
)
#验证某个示例  查看过程
qa.run(examples[0]["query"])

#模型链路回答
langchain.debug=False
predictions=qa.apply(examples)
from langchain.evaluation.qa import QAEvaluator
#评估结果
eval_chain=QAEvalChain.from_llm(llm)
graded_outputs=eval_chain.evaluate(examples,predictions)
for i,eg in enumerate(examples):
    print(f"Example {i}:")
    print(f"Query: {predictions[i]['query']}")
    print(f"Real Answer: {predictions[i]['answer']}")
    print("predicted answer:"+predictions[i]['result'])
    print(f"Grade: {graded_outputs[i]['text']}")











